{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_FFAzI-jAaF"
      },
      "source": [
        "## Что такое большие данные и почему для работы с ними нужны отдельные подходы.\n",
        "\n",
        "*В Одноклассниках большие данные и размер кластера исчисляется сотнями петабайт.* \n",
        "\n",
        "### **Big Data** это:\n",
        "\n",
        "- __Сами массивы данных.__\n",
        "- __Инструменты.__ Метатермин в наше время, не относится к самим данным.\n",
        "- __Подходы и методы их обработки.__\n",
        "\n",
        "**Любое использование больших данных** — это:\n",
        "\n",
        "1. Дорого.\n",
        "2. Должно себя окупать"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Методика работы с BigData\n",
        "__Работу выполнили:__\n",
        "\n",
        "1. Алсу Бадртдинова\n",
        "2. Лия Камалова\n",
        "3. Ильзира Ахметдинова\n",
        "\n",
        "__Верхнеуровневый план работы:__\n",
        "\n",
        "* Опишем методику работы с Big data с помощью Spark и объясним необходимость существования подобных инструментов. \n",
        "* Возможности Spark в генерации данных с использованием библиотеки dbldatagen. \n",
        "* Рассмотрим операции парсинга, конкатенции, поиска, фильтрации.\n",
        "* Оценим временную сложность основных операций. "
      ],
      "metadata": {
        "id": "CHm3NVezvhO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DASK\n"
      ],
      "metadata": {
        "id": "jb397MChirRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dask — это библиотека анализа данных с обеспечением параллельных вычислений и масштабируемой производительностью, а также с интеграцией с другими Python-инструментами: Numpy, Pandas и Scikit-learn. Библиотека имеет в основе существующие API-интерфейсы на Python и структуры данных, чтобы упростить переключение между библиотеками.\n",
        "\n",
        "Датафреймы Dask не полностью совместимы с Pandas, но некоторые наиболее распространенные операции обработки данных всё же поддерживаются обоими библиотеками. Dask больше ориентирован на масштабирование с вычислениями на кластерах.\n"
      ],
      "metadata": {
        "id": "hX1d4RtOHDup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"dask[complete]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvmbBGWbG9r1",
        "outputId": "9a9d62f5-56c1-475c-b3f3-cc8782e1e2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.0)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (4.2.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (21.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (5.1.1)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.1.1-py3-none-any.whl (830 kB)\n",
            "\u001b[K     |████████████████████████████████| 830 kB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.2.0)\n",
            "Collecting cloudpickle>=0.2.1\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.0.3)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 26.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 47.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 50.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (57.4.0)\n",
            "  Downloading distributed-2021.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 52.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.10.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 50.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 60.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 58.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
            "\u001b[K     |████████████████████████████████| 778 kB 59.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.0-py3-none-any.whl (776 kB)\n",
            "\u001b[K     |████████████████████████████████| 776 kB 53.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 52.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.1-py3-none-any.whl (766 kB)\n",
            "\u001b[K     |████████████████████████████████| 766 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 26.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 56.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.1-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.0-py3-none-any.whl (715 kB)\n",
            "\u001b[K     |████████████████████████████████| 715 kB 46.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.1-py3-none-any.whl (705 kB)\n",
            "\u001b[K     |████████████████████████████████| 705 kB 56.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 57.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 31.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.0-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 55.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.1-py3-none-any.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 54.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 47.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.2.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 56.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.1-py3-none-any.whl (672 kB)\n",
            "\u001b[K     |████████████████████████████████| 672 kB 56.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.0-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 41.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2020.12.0-py3-none-any.whl (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 57.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0->dask[complete]) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[complete]) (2022.1)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]) (1.0.1)\n",
            "Installing collected packages: locket, cloudpickle, partd, fsspec, distributed\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.1.0 distributed-2.30.1 fsspec-2022.5.0 locket-1.0.0 partd-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dask"
      ],
      "metadata": {
        "id": "WATFqBmVG8AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05523f5-dbbe-4e0d-cc70-0ec6ec868b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dask Array работает с очень большими массивами, разделяя их на куски и выполняя эти блоки параллельно. \n",
        "\n",
        "Dask Array может читать из любого массива"
      ],
      "metadata": {
        "id": "RDHkOqYLHM1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import dask.dataframe as dd"
      ],
      "metadata": {
        "id": "k7NRtNteHIDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2df17e6e"
      },
      "source": [
        "Граф выполнения Dask при чтении нескольких файлов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2d694c"
      },
      "source": [
        "Датафрейм Dask состоит из нескольких датафреймов pandas, которые разделены по индексам. Когда мы выполняем функцию read_csv из Dask, выполняется чтение одного и того же файла несколькими процессами.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33d19db4"
      },
      "source": [
        "Чтение CSV-файлов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9f30379"
      },
      "source": [
        "ЕСли есть много CSV-файлов , мы  можем прочитать их все как один логический кадр данных, используя dd.read_csv функцию со строкой glob."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33e1c3ce"
      },
      "source": [
        "Мы можем прочитать один файл с помощью pandas.read_csv или несколько файлов с помощьюdask.dataframe.read_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03b29339"
      },
      "source": [
        "Читать с Паркета\n",
        "\n",
        "\n",
        "Всякий раз, когда мы работаем с нашим фреймом данных, мы читаем все наши данные CSV, чтобы не заполнять ОЗУ. Это очень эффективно для использования памяти, но чтение всех файлов CSV каждый раз может быть медленным.\n",
        "\n",
        "Вместо этого можно хранить наши данные в формате Parquet, который более эффективен для компьютеров при чтении и записи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdc35833"
      },
      "source": [
        "\n",
        "Parquet — это хранилище столбцов, что означает, что он может эффективно извлекать только несколько столбцов из вашего набора данных. Это хорошо, потому что помогает избежать ненужной загрузки данных."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install \"dask[complete]\""
      ],
      "metadata": {
        "id": "ppKa4PPFD7Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a61eb52-98d0-4706-b12b-d761659f97cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: distributed>=2.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.30.1)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.1.0)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.2.0)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (4.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (21.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (5.1.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.2.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0->dask[complete]) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[complete]) (2022.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[complete]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pandas import json_normalize"
      ],
      "metadata": {
        "id": "uPinhARMEEaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Парсинг данных\n"
      ],
      "metadata": {
        "id": "DPqf93KQux9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd"
      ],
      "metadata": {
        "id": "ZcLoi9e7wM4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "BYi2mXiBu5ke",
        "outputId": "421c748e-d4d3-4ec6-8649-6c02141817ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e87d323e-2e44-43a3-8316-9f270375f2ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e87d323e-2e44-43a3-8316-9f270375f2ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving airport-codes.csv to airport-codes (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/airport-codes.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyaPutaL1ExE",
        "outputId": "6dec0842-fef7-4ea3-917d-0a67c444654a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57421 entries, 0 to 57420\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   ident         57421 non-null  object \n",
            " 1   type          57421 non-null  object \n",
            " 2   name          57421 non-null  object \n",
            " 3   elevation_ft  49608 non-null  float64\n",
            " 4   continent     28978 non-null  object \n",
            " 5   iso_country   57175 non-null  object \n",
            " 6   iso_region    57421 non-null  object \n",
            " 7   municipality  51527 non-null  object \n",
            " 8   gps_code      41561 non-null  object \n",
            " 9   iata_code     9225 non-null   object \n",
            " 10  local_code    30030 non-null  object \n",
            " 11  coordinates   57421 non-null  object \n",
            "dtypes: float64(1), object(11)\n",
            "memory usage: 5.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ddxzInjqZMcL",
        "outputId": "d0e1ca75-b00b-44be-969d-e58d0696ef9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ident           type                                name  elevation_ft  \\\n",
              "0   00A       heliport                   Total Rf Heliport          11.0   \n",
              "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
              "2  00AK  small_airport                        Lowell Field         450.0   \n",
              "3  00AL  small_airport                        Epps Airpark         820.0   \n",
              "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
              "\n",
              "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
              "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
              "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
              "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
              "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
              "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
              "\n",
              "  local_code                            coordinates  \n",
              "0        00A     -74.93360137939453, 40.07080078125  \n",
              "1       00AA                 -101.473911, 38.704022  \n",
              "2       00AK            -151.695999146, 59.94919968  \n",
              "3       00AL  -86.77030181884766, 34.86479949951172  \n",
              "4        NaN                    -91.254898, 35.6087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caac8269-3188-4dbc-a396-6c28930315be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ident</th>\n",
              "      <th>type</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_ft</th>\n",
              "      <th>continent</th>\n",
              "      <th>iso_country</th>\n",
              "      <th>iso_region</th>\n",
              "      <th>municipality</th>\n",
              "      <th>gps_code</th>\n",
              "      <th>iata_code</th>\n",
              "      <th>local_code</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00A</td>\n",
              "      <td>heliport</td>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-PA</td>\n",
              "      <td>Bensalem</td>\n",
              "      <td>00A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00A</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00AA</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>3435.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-KS</td>\n",
              "      <td>Leoti</td>\n",
              "      <td>00AA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AA</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00AK</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>450.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AK</td>\n",
              "      <td>Anchor Point</td>\n",
              "      <td>00AK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AK</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00AL</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>820.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AL</td>\n",
              "      <td>Harvest</td>\n",
              "      <td>00AL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AL</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00AR</td>\n",
              "      <td>closed</td>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>237.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AR</td>\n",
              "      <td>Newport</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caac8269-3188-4dbc-a396-6c28930315be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caac8269-3188-4dbc-a396-6c28930315be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caac8269-3188-4dbc-a396-6c28930315be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hfZFgPPZZXOU",
        "outputId": "a2e9a24a-39af-4016-a262-bb544c383b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ident            type                       name  elevation_ft  \\\n",
              "57416     ZYYK  medium_airport      Yingkou Lanqi Airport           0.0   \n",
              "57417     ZYYY  medium_airport    Shenyang Dongta Airport           NaN   \n",
              "57418  ZZ-0001        heliport            Sealand Helipad          40.0   \n",
              "57419  ZZ-0002   small_airport  Glorioso Islands Airstrip          11.0   \n",
              "57420     ZZZZ   small_airport    Satsuma IÅjima Airport         338.0   \n",
              "\n",
              "      continent iso_country iso_region      municipality gps_code iata_code  \\\n",
              "57416        AS          CN      CN-21           Yingkou     ZYYK       YKH   \n",
              "57417        AS          CN      CN-21          Shenyang     ZYYY       NaN   \n",
              "57418        EU          GB     GB-ENG           Sealand      NaN       NaN   \n",
              "57419        AF          TF     TF-U-A  Grande Glorieuse      NaN       NaN   \n",
              "57420        AS          JP      JP-46      Mishima-Mura     RJX7       NaN   \n",
              "\n",
              "      local_code                              coordinates  \n",
              "57416        NaN                      122.3586, 40.542524  \n",
              "57417        NaN   123.49600219726562, 41.784400939941406  \n",
              "57418        NaN                        1.4825, 51.894444  \n",
              "57419        NaN  47.296388888900005, -11.584277777799999  \n",
              "57420       RJX7                    130.270556, 30.784722  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6acc12f3-a862-403e-b6f3-ba5edeecc9cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ident</th>\n",
              "      <th>type</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_ft</th>\n",
              "      <th>continent</th>\n",
              "      <th>iso_country</th>\n",
              "      <th>iso_region</th>\n",
              "      <th>municipality</th>\n",
              "      <th>gps_code</th>\n",
              "      <th>iata_code</th>\n",
              "      <th>local_code</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57416</th>\n",
              "      <td>ZYYK</td>\n",
              "      <td>medium_airport</td>\n",
              "      <td>Yingkou Lanqi Airport</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AS</td>\n",
              "      <td>CN</td>\n",
              "      <td>CN-21</td>\n",
              "      <td>Yingkou</td>\n",
              "      <td>ZYYK</td>\n",
              "      <td>YKH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>122.3586, 40.542524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57417</th>\n",
              "      <td>ZYYY</td>\n",
              "      <td>medium_airport</td>\n",
              "      <td>Shenyang Dongta Airport</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AS</td>\n",
              "      <td>CN</td>\n",
              "      <td>CN-21</td>\n",
              "      <td>Shenyang</td>\n",
              "      <td>ZYYY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>123.49600219726562, 41.784400939941406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57418</th>\n",
              "      <td>ZZ-0001</td>\n",
              "      <td>heliport</td>\n",
              "      <td>Sealand Helipad</td>\n",
              "      <td>40.0</td>\n",
              "      <td>EU</td>\n",
              "      <td>GB</td>\n",
              "      <td>GB-ENG</td>\n",
              "      <td>Sealand</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.4825, 51.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57419</th>\n",
              "      <td>ZZ-0002</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Glorioso Islands Airstrip</td>\n",
              "      <td>11.0</td>\n",
              "      <td>AF</td>\n",
              "      <td>TF</td>\n",
              "      <td>TF-U-A</td>\n",
              "      <td>Grande Glorieuse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.296388888900005, -11.584277777799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57420</th>\n",
              "      <td>ZZZZ</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Satsuma IÅjima Airport</td>\n",
              "      <td>338.0</td>\n",
              "      <td>AS</td>\n",
              "      <td>JP</td>\n",
              "      <td>JP-46</td>\n",
              "      <td>Mishima-Mura</td>\n",
              "      <td>RJX7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RJX7</td>\n",
              "      <td>130.270556, 30.784722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6acc12f3-a862-403e-b6f3-ba5edeecc9cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6acc12f3-a862-403e-b6f3-ba5edeecc9cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6acc12f3-a862-403e-b6f3-ba5edeecc9cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_parquet('11.parquet', engine='pyarrow')"
      ],
      "metadata": {
        "id": "8yE3j6xu04pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-sMUYSCuZWkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dd.read_parquet('11.parquet', columns=['name', 'coordinates'], engine='pyarrow')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4uobcoyw-3p",
        "outputId": "dc508753-e1d3-4953-f976-78331d774011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dask.dataframe.core.DataFrame'>\n",
            "Columns: 2 entries, name to coordinates\n",
            "dtypes: object(2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qqoe32I4J5sr",
        "outputId": "b258e4c5-2375-4e58-c085-db6dcf613845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 name                            coordinates\n",
              "0                   Total Rf Heliport     -74.93360137939453, 40.07080078125\n",
              "1                Aero B Ranch Airport                 -101.473911, 38.704022\n",
              "2                        Lowell Field            -151.695999146, 59.94919968\n",
              "3                        Epps Airpark  -86.77030181884766, 34.86479949951172\n",
              "4  Newport Hospital & Clinic Heliport                    -91.254898, 35.6087"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98ff3709-960e-4416-8e61-ed39c586d2a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98ff3709-960e-4416-8e61-ed39c586d2a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98ff3709-960e-4416-8e61-ed39c586d2a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98ff3709-960e-4416-8e61-ed39c586d2a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0kfN-A5qJ9pH",
        "outputId": "5f8d6b2a-1e22-4056-eaa2-2d27e9002180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            name                              coordinates\n",
              "57416      Yingkou Lanqi Airport                      122.3586, 40.542524\n",
              "57417    Shenyang Dongta Airport   123.49600219726562, 41.784400939941406\n",
              "57418            Sealand Helipad                        1.4825, 51.894444\n",
              "57419  Glorioso Islands Airstrip  47.296388888900005, -11.584277777799999\n",
              "57420    Satsuma IÅjima Airport                    130.270556, 30.784722"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-692a4473-1e6b-43d0-92b7-6b9a5163658b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57416</th>\n",
              "      <td>Yingkou Lanqi Airport</td>\n",
              "      <td>122.3586, 40.542524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57417</th>\n",
              "      <td>Shenyang Dongta Airport</td>\n",
              "      <td>123.49600219726562, 41.784400939941406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57418</th>\n",
              "      <td>Sealand Helipad</td>\n",
              "      <td>1.4825, 51.894444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57419</th>\n",
              "      <td>Glorioso Islands Airstrip</td>\n",
              "      <td>47.296388888900005, -11.584277777799999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57420</th>\n",
              "      <td>Satsuma IÅjima Airport</td>\n",
              "      <td>130.270556, 30.784722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-692a4473-1e6b-43d0-92b7-6b9a5163658b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-692a4473-1e6b-43d0-92b7-6b9a5163658b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-692a4473-1e6b-43d0-92b7-6b9a5163658b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfz4e8ZBKbn6",
        "outputId": "5e7ae83b-aca7-4c21-e7f2-983f6f387a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dask.dataframe.core.DataFrame'>\n",
            "Columns: 2 entries, name to coordinates\n",
            "dtypes: object(2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import isnan"
      ],
      "metadata": {
        "id": "BvBBeLyzKdCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dd.read_csv('/content/airport-codes.csv')"
      ],
      "metadata": {
        "id": "QpBD5Qr6aypQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конкатенация\n"
      ],
      "metadata": {
        "id": "iJkMogfibfLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = dd.concat([df, data], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_aYZh6BZrUc",
        "outputId": "1f505130-822e-47f1-8385-904d5a23e7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dask/dataframe/multi.py:1056: UserWarning: Concatenating dataframes with unknown divisions.\n",
            "We're assuming that the indexes of each dataframes are \n",
            " aligned. This assumption is not generally safe.\n",
            "  \"Concatenating dataframes with unknown divisions.\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSX5_OrWbBjd",
        "outputId": "0279f490-70e4-4470-9a1a-980b1ecb4c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dask.dataframe.core.DataFrame'>\n",
            "Columns: 14 entries, name to coordinates\n",
            "dtypes: object(13), float64(1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "OAmtgTQfbGxO",
        "outputId": "b83d97a9-a780-4648-b1c6-212ba7617a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 name                            coordinates  \\\n",
              "0                   Total Rf Heliport     -74.93360137939453, 40.07080078125   \n",
              "1                Aero B Ranch Airport                 -101.473911, 38.704022   \n",
              "2                        Lowell Field            -151.695999146, 59.94919968   \n",
              "3                        Epps Airpark  -86.77030181884766, 34.86479949951172   \n",
              "4  Newport Hospital & Clinic Heliport                    -91.254898, 35.6087   \n",
              "\n",
              "  ident           type                                name  elevation_ft  \\\n",
              "0   00A       heliport                   Total Rf Heliport          11.0   \n",
              "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
              "2  00AK  small_airport                        Lowell Field         450.0   \n",
              "3  00AL  small_airport                        Epps Airpark         820.0   \n",
              "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
              "\n",
              "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
              "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
              "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
              "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
              "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
              "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
              "\n",
              "  local_code                            coordinates  \n",
              "0        00A     -74.93360137939453, 40.07080078125  \n",
              "1       00AA                 -101.473911, 38.704022  \n",
              "2       00AK            -151.695999146, 59.94919968  \n",
              "3       00AL  -86.77030181884766, 34.86479949951172  \n",
              "4        NaN                    -91.254898, 35.6087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c446221c-ef7d-4311-8cde-0b18f97fed99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>ident</th>\n",
              "      <th>type</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_ft</th>\n",
              "      <th>continent</th>\n",
              "      <th>iso_country</th>\n",
              "      <th>iso_region</th>\n",
              "      <th>municipality</th>\n",
              "      <th>gps_code</th>\n",
              "      <th>iata_code</th>\n",
              "      <th>local_code</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "      <td>00A</td>\n",
              "      <td>heliport</td>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-PA</td>\n",
              "      <td>Bensalem</td>\n",
              "      <td>00A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00A</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "      <td>00AA</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>3435.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-KS</td>\n",
              "      <td>Leoti</td>\n",
              "      <td>00AA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AA</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "      <td>00AK</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>450.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AK</td>\n",
              "      <td>Anchor Point</td>\n",
              "      <td>00AK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AK</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "      <td>00AL</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>820.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AL</td>\n",
              "      <td>Harvest</td>\n",
              "      <td>00AL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00AL</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "      <td>00AR</td>\n",
              "      <td>closed</td>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>237.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AR</td>\n",
              "      <td>Newport</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c446221c-ef7d-4311-8cde-0b18f97fed99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c446221c-ef7d-4311-8cde-0b18f97fed99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c446221c-ef7d-4311-8cde-0b18f97fed99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства заполним пропуски нулями"
      ],
      "metadata": {
        "id": "cFDWDBhHb9ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2= df1.fillna(0)"
      ],
      "metadata": {
        "id": "DKXEA24ibOvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "N_bK0BRhcFbk",
        "outputId": "b7f2426c-5f49-4b91-ae3a-90353958b24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 name                            coordinates  \\\n",
              "0                   Total Rf Heliport     -74.93360137939453, 40.07080078125   \n",
              "1                Aero B Ranch Airport                 -101.473911, 38.704022   \n",
              "2                        Lowell Field            -151.695999146, 59.94919968   \n",
              "3                        Epps Airpark  -86.77030181884766, 34.86479949951172   \n",
              "4  Newport Hospital & Clinic Heliport                    -91.254898, 35.6087   \n",
              "\n",
              "  ident           type                                name  elevation_ft  \\\n",
              "0   00A       heliport                   Total Rf Heliport          11.0   \n",
              "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
              "2  00AK  small_airport                        Lowell Field         450.0   \n",
              "3  00AL  small_airport                        Epps Airpark         820.0   \n",
              "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
              "\n",
              "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
              "0         0          US      US-PA      Bensalem      00A         0   \n",
              "1         0          US      US-KS         Leoti     00AA         0   \n",
              "2         0          US      US-AK  Anchor Point     00AK         0   \n",
              "3         0          US      US-AL       Harvest     00AL         0   \n",
              "4         0          US      US-AR       Newport        0         0   \n",
              "\n",
              "  local_code                            coordinates  \n",
              "0        00A     -74.93360137939453, 40.07080078125  \n",
              "1       00AA                 -101.473911, 38.704022  \n",
              "2       00AK            -151.695999146, 59.94919968  \n",
              "3       00AL  -86.77030181884766, 34.86479949951172  \n",
              "4          0                    -91.254898, 35.6087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-127aad28-dcd6-48fb-a34e-1d861d282d03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>ident</th>\n",
              "      <th>type</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_ft</th>\n",
              "      <th>continent</th>\n",
              "      <th>iso_country</th>\n",
              "      <th>iso_region</th>\n",
              "      <th>municipality</th>\n",
              "      <th>gps_code</th>\n",
              "      <th>iata_code</th>\n",
              "      <th>local_code</th>\n",
              "      <th>coordinates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "      <td>00A</td>\n",
              "      <td>heliport</td>\n",
              "      <td>Total Rf Heliport</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>US-PA</td>\n",
              "      <td>Bensalem</td>\n",
              "      <td>00A</td>\n",
              "      <td>0</td>\n",
              "      <td>00A</td>\n",
              "      <td>-74.93360137939453, 40.07080078125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "      <td>00AA</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Aero B Ranch Airport</td>\n",
              "      <td>3435.0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>US-KS</td>\n",
              "      <td>Leoti</td>\n",
              "      <td>00AA</td>\n",
              "      <td>0</td>\n",
              "      <td>00AA</td>\n",
              "      <td>-101.473911, 38.704022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "      <td>00AK</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Lowell Field</td>\n",
              "      <td>450.0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AK</td>\n",
              "      <td>Anchor Point</td>\n",
              "      <td>00AK</td>\n",
              "      <td>0</td>\n",
              "      <td>00AK</td>\n",
              "      <td>-151.695999146, 59.94919968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "      <td>00AL</td>\n",
              "      <td>small_airport</td>\n",
              "      <td>Epps Airpark</td>\n",
              "      <td>820.0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AL</td>\n",
              "      <td>Harvest</td>\n",
              "      <td>00AL</td>\n",
              "      <td>0</td>\n",
              "      <td>00AL</td>\n",
              "      <td>-86.77030181884766, 34.86479949951172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "      <td>00AR</td>\n",
              "      <td>closed</td>\n",
              "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
              "      <td>237.0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "      <td>US-AR</td>\n",
              "      <td>Newport</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-91.254898, 35.6087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-127aad28-dcd6-48fb-a34e-1d861d282d03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-127aad28-dcd6-48fb-a34e-1d861d282d03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-127aad28-dcd6-48fb-a34e-1d861d282d03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Фильтрация"
      ],
      "metadata": {
        "id": "AMrVvImDi38Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continent = data[data['continent']=='EU']"
      ],
      "metadata": {
        "id": "voUCVf0CcY9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continent[['name', 'continent']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HY2XzmUNda0Q",
        "outputId": "cca8e78f-0d80-463a-ed2d-9cdd37d18524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            name continent\n",
              "10422               RAF Calveley        EU\n",
              "10423           RNAS/RAF Calshot        EU\n",
              "10426             CamÃ­ Heliport        EU\n",
              "10427  Andorra la Vella Heliport        EU\n",
              "10429             RAF Castletown        EU"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62b6a657-4e27-469e-97b9-3664a63484f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>continent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10422</th>\n",
              "      <td>RAF Calveley</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10423</th>\n",
              "      <td>RNAS/RAF Calshot</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10426</th>\n",
              "      <td>CamÃ­ Heliport</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10427</th>\n",
              "      <td>Andorra la Vella Heliport</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10429</th>\n",
              "      <td>RAF Castletown</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62b6a657-4e27-469e-97b9-3664a63484f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62b6a657-4e27-469e-97b9-3664a63484f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62b6a657-4e27-469e-97b9-3664a63484f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask-searchcv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cn8O9nekjWh",
        "outputId": "7668fa5c-dc4f-458f-f132-97ff154d4cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dask-searchcv\n",
            "  Downloading dask_searchcv-0.2.0-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from dask-searchcv) (1.0.2)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask-searchcv) (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from dask-searchcv) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from dask-searchcv) (1.4.1)\n",
            "Requirement already satisfied: dask>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from dask-searchcv) (2.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->dask-searchcv) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->dask-searchcv) (1.1.0)\n",
            "Installing collected packages: dask-searchcv\n",
            "Successfully installed dask-searchcv-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns1 = ['heliport', 'small_airport']"
      ],
      "metadata": {
        "id": "TX9sLSaTqZGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['iso_country', 'type']).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DeUpE3Buquo",
        "outputId": "c6cb7fcd-2515-4287-9886-980403c36eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask Series Structure:\n",
              "npartitions=1\n",
              "    int64\n",
              "      ...\n",
              "dtype: int64\n",
              "Dask Name: dataframe-groupby-size-agg, 5 tasks"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddf_selected = data.loc[data['type']]"
      ],
      "metadata": {
        "id": "SvUgpmxbkduo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gzCm1QtAvPec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "LAUjZIPXxktN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas.tseries\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcNrkfIMyA8o",
        "outputId": "1513c1ac-154c-4a5b-f05b-751da36706cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize =(11,9))\n",
        "plt.title(\"Распределение высоты\")\n",
        "sns.distplot(data.elevation_ft)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "PsmWvao1wqI0",
        "outputId": "b0b4ebf3-fb70-4e62-f3d5-3d1996b32d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HYwUMvduzD_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z78RxkSkhVWQ"
      },
      "source": [
        "# __Spark for Big Data. Introduction__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZkgw5WjkJhX"
      },
      "source": [
        "**Spark** —  современный и высокоуровневый инструмент для обработки больших массивов информации. Самый распространённый фреймворк для работы с ML на больших данных и расчетов на них. \n",
        "\n",
        "- Индустриальный стандарт.\n",
        "- Под капотом **Spark** написан на Scala, поэтому через *Scala вызовы* на него самый богатый доступ к **API**.\n",
        "- __Scala__ - это JVM friendly язык, поэтому вся логика Spark будет транслироваться в поток байт для JVM.\n",
        "- В питоновских структурах данных есть проблемы, так как Python медленнее Scala. Scala в некоторых тестах может быть в несколько раз или на порядки быстрее Python. Есть бенчмарки, оформленные в виде статей от Димы Бугайченко.\n",
        "- **PySpark** хватает для 90 процентов задач, остальные 10 процентов будут не так эффективны, но даже они не сильно критичны для маленьких кластеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg-hKpnMiiQt"
      },
      "source": [
        "__Полезные ссылки по Spark:__\n",
        "\n",
        "* [RDD Programming Guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
        "* [PairRDDFunctions](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
        "\n",
        "__Документация по Spark:__\n",
        "\n",
        "* PySpark: [https://spark.apache.org/docs/latest/api/python/index.html](https://spark.apache.org/docs/latest/api/python/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWRgQEPJlHHS"
      },
      "source": [
        "### Part 0. Load data, Import libs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdoSReETw2G0"
      },
      "source": [
        "__Импортируем необходимые библиотеки__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtKw7fCMmOih"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG8Jj8t1laud"
      },
      "source": [
        "__Установим Spark в Google Colab__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N34jNAaogUEr",
        "outputId": "5f9ef4ac-75ca-4b21-ed35-61847238a707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.1-bin-hadoop3.2/\n",
            "spark-3.2.1-bin-hadoop3.2/LICENSE\n",
            "spark-3.2.1-bin-hadoop3.2/NOTICE\n",
            "spark-3.2.1-bin-hadoop3.2/R/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/INDEX\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/R.css\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n",
            "spark-3.2.1-bin-hadoop3.2/R/lib/sparkr.zip\n",
            "spark-3.2.1-bin-hadoop3.2/README.md\n",
            "spark-3.2.1-bin-hadoop3.2/RELEASE\n",
            "spark-3.2.1-bin-hadoop3.2/bin/\n",
            "spark-3.2.1-bin-hadoop3.2/bin/beeline\n",
            "spark-3.2.1-bin-hadoop3.2/bin/beeline.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/docker-image-tool.sh\n",
            "spark-3.2.1-bin-hadoop3.2/bin/find-spark-home\n",
            "spark-3.2.1-bin-hadoop3.2/bin/find-spark-home.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.sh\n",
            "spark-3.2.1-bin-hadoop3.2/bin/pyspark\n",
            "spark-3.2.1-bin-hadoop3.2/bin/pyspark.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/pyspark2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/run-example\n",
            "spark-3.2.1-bin-hadoop3.2/bin/run-example.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-class\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-class.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-class2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-shell\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-shell.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-shell2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-sql\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-sql.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-sql2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-submit\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-submit.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/spark-submit2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/sparkR\n",
            "spark-3.2.1-bin-hadoop3.2/bin/sparkR.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/bin/sparkR2.cmd\n",
            "spark-3.2.1-bin-hadoop3.2/conf/\n",
            "spark-3.2.1-bin-hadoop3.2/conf/fairscheduler.xml.template\n",
            "spark-3.2.1-bin-hadoop3.2/conf/log4j.properties.template\n",
            "spark-3.2.1-bin-hadoop3.2/conf/metrics.properties.template\n",
            "spark-3.2.1-bin-hadoop3.2/conf/spark-defaults.conf.template\n",
            "spark-3.2.1-bin-hadoop3.2/conf/spark-env.sh.template\n",
            "spark-3.2.1-bin-hadoop3.2/conf/workers.template\n",
            "spark-3.2.1-bin-hadoop3.2/data/\n",
            "spark-3.2.1-bin-hadoop3.2/data/graphx/\n",
            "spark-3.2.1-bin-hadoop3.2/data/graphx/followers.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/graphx/users.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/als/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/als/test.data\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/gmm_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/license.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/license.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/kmeans_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/pagerank_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/pic_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.2.1-bin-hadoop3.2/data/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/data/streaming/AFINN-111.txt\n",
            "spark-3.2.1-bin-hadoop3.2/examples/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/jars/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/als.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/kmeans.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pagerank.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pi.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sort.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/wordcount.py\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/dataframe.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/als.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/employees.json\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.csv\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.json\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.txt\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/user.avsc\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.avro\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.orc\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/\n",
            "spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.2.1-bin-hadoop3.2/jars/\n",
            "spark-3.2.1-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/JTransforms-3.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/ST4-4.0.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/activation-1.1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/aircompressor-0.21.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/annotations-17.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/antlr4-runtime-4.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arpack-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arrow-format-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/automaton-1.11-8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/avro-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/avro-ipc-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/avro-mapred-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/blas-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/breeze-macros_2.12-1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/breeze_2.12-1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/chill-java-0.10.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-cli-1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-codec-1.15.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-compress-1.21.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-io-2.8.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-lang-2.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-net-3.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/commons-text-1.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/core-1.1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/derby-10.14.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/generex-1.0.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/gson-2.2.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/guava-14.0.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-api-3.3.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-runtime-3.3.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.3.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-cli-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-serde-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/httpclient-4.5.13.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/httpcore-4.4.14.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-annotations-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-core-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-databind-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/janino-3.0.16.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/javolution-5.5.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-client-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-common-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-core-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-hk2-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jersey-server-2.34.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jline-2.14.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/joda-time-2.10.10.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jpam-1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/json-1.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jta-1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-client-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-admissionregistration-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apiextensions-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apps-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-autoscaling-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-batch-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-certificates-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-common-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-coordination-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-core-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-discovery-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-events-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-extensions-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-flowcontrol-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-metrics-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-networking-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-node-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-policy-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-rbac-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-scheduling-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-storageclass-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/lapack-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/log4j-1.2.17.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/metrics-core-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/metrics-graphite-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/metrics-jmx-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/metrics-json-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/metrics-jvm-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/minlog-1.3.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/netty-all-4.1.68.Final.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/objenesis-2.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/okhttp-3.12.12.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/okio-1.14.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/opencsv-2.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/orc-core-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/orc-mapreduce-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/orc-shims-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/oro-2.0.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/paranamer-2.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-column-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-common-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-encoding-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-format-structures-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-hadoop-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/parquet-jackson-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/py4j-0.10.9.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/pyrolite-4.30.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/rocksdbjni-6.20.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-compiler-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-library-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-reflect-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/shims-0.9.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/snakeyaml-1.27.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/snappy-java-1.1.8.4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-catalyst_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-core_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-graphx_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-hive_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-kvstore_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-launcher_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-mesos_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-mllib_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-network-common_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-repl_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-sketch_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-sql_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-streaming_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1-tests.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spark-yarn_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/stream-2.9.6.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/tink-1.6.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/transaction-api-1.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/velocity-1.5.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/xbean-asm9-shaded-4.20.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/xz-1.8.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/zookeeper-3.6.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/zookeeper-jute-3.6.2.jar\n",
            "spark-3.2.1-bin-hadoop3.2/jars/zstd-jni-1.5.0-4.jar\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/autoscale.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n",
            "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-blas.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-janino.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javassist.html\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jline.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-join.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-respond.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scala.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-spire.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/\n",
            "spark-3.2.1-bin-hadoop3.2/python/.coveragerc\n",
            "spark-3.2.1-bin-hadoop3.2/python/.gitignore\n",
            "spark-3.2.1-bin-hadoop3.2/python/MANIFEST.in\n",
            "spark-3.2.1-bin-hadoop3.2/python/README.md\n",
            "spark-3.2.1-bin-hadoop3.2/python/dist/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/Makefile\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/make.bat\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/make2.bat\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/copybutton.js\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/conf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/contributing.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/debugging.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/setting_ide.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/testing.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/install.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.2.1-bin-hadoop3.2/python/lib/\n",
            "spark-3.2.1-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/lib/py4j-0.10.9.3-src.zip\n",
            "spark-3.2.1-bin-hadoop3.2/python/lib/pyspark.zip\n",
            "spark-3.2.1-bin-hadoop3.2/python/mypy.ini\n",
            "spark-3.2.1-bin-hadoop3.2/python/pylintrc\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/_globals.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/context.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/daemon.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/files.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/files.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/find_spark_home.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/install.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/java_gateway.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/join.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/_typing.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/accessors.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/categorical.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/config.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/datetimes.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/exceptions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/extensions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/frame.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/generic.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/groupby.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexing.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/internal.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/common.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/series.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/window.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/ml.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/mlflow.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/namespace.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/core.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/series.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/strings.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/string_typehints.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/window.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/py.typed\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/rddsampler.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/serializers.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/shell.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/shuffle.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/status.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/status.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/pandasutils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_join.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/traceback_utils.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/util.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/util.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/version.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/version.pyi\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark/worker.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/requires.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/run-tests\n",
            "spark-3.2.1-bin-hadoop3.2/python/run-tests-with-coverage\n",
            "spark-3.2.1-bin-hadoop3.2/python/run-tests.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/setup.cfg\n",
            "spark-3.2.1-bin-hadoop3.2/python/setup.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_coverage/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/hello.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages.csv\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people.json\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people1.json\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array.json\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/text-test.txt\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n",
            "spark-3.2.1-bin-hadoop3.2/python/test_support/userlibrary.py\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/decommission-slave.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/decommission-worker.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/slaves.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/spark-config.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/spark-daemon.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/spark-daemons.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-all.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-history-server.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-master.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-slave.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-slaves.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-thriftserver.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-worker.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/start-workers.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-all.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-history-server.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-master.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-slave.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-slaves.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-thriftserver.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-worker.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/stop-workers.sh\n",
            "spark-3.2.1-bin-hadoop3.2/sbin/workers.sh\n",
            "spark-3.2.1-bin-hadoop3.2/yarn/\n",
            "spark-3.2.1-bin-hadoop3.2/yarn/spark-3.2.1-yarn-shuffle.jar\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -q openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!tar xvf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5mJmM5Z8V6I",
        "outputId": "685d4520-c3e8-4332-ca04-28590e4237f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 26 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 36.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=b1e7f96d393aff3796a8634516eac1643f8b157384416362bb1d7750e98b9277\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxrh8PTSxNXU"
      },
      "source": [
        "Откроем Spark сессию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9OkWQGdlpNt"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .appName(\"Python Spark basic example\")\n",
        "    .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjN46odv50i6"
      },
      "source": [
        "### Part II. Spark for Big Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M82NReVZvA-l"
      },
      "source": [
        "__Полезные практики в Spark:__\n",
        "\n",
        "* Полезно обратить внимание на функции из **pyspark.sql.functions**. У Spark'а большой набор встроенных функций. Перед тем, как написать свою пользовательскую функцию через lambda (используется в коде в духе .map(lambda x: <some logic>)), лучше поискать функции в **pyspark.sql.functions** и на их основе попытаться скомбинировать свою. Даже если для этого потребуется 5-6 функций для создания своей логики - это будет все равно быстрее, чем если писать функцию на Python. Так как будет тратиться время на се(-де)риализацию в JVM.\n",
        "* В Spark много встроенных методов для работы со словарями, списками и в целом со структурами данных. Многое из них лежит в pyspark.sql.functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wUzT3HG6HPB"
      },
      "source": [
        "__RDD vs Spark Dataframe.__\n",
        "\n",
        "* __RDD__ – это базовый концепт того, как работать с данными в Spark. По сути это логический план вычислений, который в конце транслируется в физический план запросы для выполнения в JVM.\n",
        "\n",
        "* __Spark Dataframe__ – это структурированная колоночная структура данных. Может быть создана на основе:\n",
        "    * локальной коллекции\n",
        "    * файла (файлов)\n",
        "    * базы данных\n",
        "    * в python работает значительно быстрее, чем RDD\n",
        "    * под капотом использует RDD\n",
        "    * позволяет выполнять произвольные SQL операции с данными\n",
        "    * аналогично RDD являются ленивыми и неизменяеыми\n",
        "\n",
        "\n",
        "* Лучше всего работать в Spark с нативной конструкцией с популярным названием _Dataframe_. Они работают намного быстрее, чем RDD. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVm7bjaF8bv6"
      },
      "source": [
        "### Part III. Spark in generating data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf-04PvY9GZW"
      },
      "source": [
        "##Simple Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hz0zO-h9I4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cac5b0b-8f64-47d1-ebb6-93a2e1647db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+--------------------+\n",
            "| id|foo|         random_uuid|\n",
            "+---+---+--------------------+\n",
            "|  0|  0|5319958b-8be8-409...|\n",
            "|  1|  1|9807035c-42f8-4a7...|\n",
            "|  2|  2|d97c40fa-d2a2-46b...|\n",
            "|  3|  0|78cf9272-e103-493...|\n",
            "|  4|  1|ece23fd1-0b60-489...|\n",
            "|  5|  2|c5298bc0-bd58-42a...|\n",
            "|  6|  0|c5b2c356-b9f7-412...|\n",
            "|  7|  1|f036e284-8a11-4b9...|\n",
            "|  8|  2|5a4938e7-3060-4ca...|\n",
            "|  9|  0|17f02a03-1d76-477...|\n",
            "+---+---+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "(\n",
        "    spark.range(10)\n",
        "    .withColumn(\"foo\", expr(\"\"\" pmod(id, 3) \"\"\"))\n",
        "    .withColumn(\"random_uuid\", expr(\"java_method('java.util.UUID', 'randomUUID')\"))   \n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GBOzgrs9yvB"
      },
      "source": [
        "#### Hard Example\n",
        "\n",
        "__Synthetic Data Generation in Spark with dbldatagen__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOZrMvdz8z9-"
      },
      "source": [
        "В следующем примере показана генерация данных в Spark с помощью библиотеки Databricks Labs Data Generator ([dbldatagen](https://databrickslabs.github.io/dbldatagen/public_docs/APIDOCS.html)) от Databricks Labs\n",
        "* синтетических имен\n",
        "* адресов электронной почты\n",
        "* использование SQL-выражения для вычисления MD5-хэшей гипотетической синтетической кредитной карты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaz0YX8YAk8R"
      },
      "source": [
        "Установим библиотеку dbldatagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-zDQ4aZ8tnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7892b257-21f3-4e4a-9e65-0661fc36837f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/databrickslabs/dbldatagen\n",
            "  Cloning https://github.com/databrickslabs/dbldatagen to /tmp/pip-req-build-x0_w48t4\n",
            "  Running command git clone -q https://github.com/databrickslabs/dbldatagen /tmp/pip-req-build-x0_w48t4\n",
            "Building wheels for collected packages: dbldatagen\n",
            "  Building wheel for dbldatagen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dbldatagen: filename=dbldatagen-0.2.0rc1-py3-none-any.whl size=68973 sha256=f59dad52634bf1163159193b8736c979f0742887e46e8e1a3c5e7df7f0b97052\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jwau0thf/wheels/fa/2f/29/fd337c2f0a1da95c1069d7f4898c3ff5a0ea697cb5d31f319c\n",
            "Successfully built dbldatagen\n",
            "Installing collected packages: dbldatagen\n",
            "Successfully installed dbldatagen-0.2.0rc1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/databrickslabs/dbldatagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT_6XDRL8m8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de87e55b-ef26-421d-e58e-4c625cc23907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Version : VersionInfo(major='0', minor='2', patch='0', release='rc', build='1')\n"
          ]
        }
      ],
      "source": [
        "import dbldatagen as dg\n",
        "\n",
        "shuffle_partitions_requested = 8\n",
        "partitions_requested = 8\n",
        "data_rows = 10000000\n",
        "\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", shuffle_partitions_requested)\n",
        "\n",
        "dataspec = (\n",
        "    dg.DataGenerator(spark, rows=data_rows, partitions=8, randomSeedMethod=\"hash_fieldname\")\n",
        "    .withColumn(\"name\", percentNulls=0.01, template=r'\\\\w \\\\w|\\\\w a. \\\\w') \n",
        "    .withColumn(\"payment_instrument_type\", values=['paypal', 'visa', 'mastercard', 'amex'], \n",
        "                random=True)             \n",
        "    .withColumn(\"int_payment_instrument\", \"int\",  minValue=0000, maxValue=9999,  \n",
        "                baseColumn=\"name\",\n",
        "                baseColumnType=\"hash\", omit=True)\n",
        "    .withColumn(\"payment_instrument\", \n",
        "                    expr=\"format_number(int_payment_instrument, '**** ****** *####')\",\n",
        "                    baseColumn=\"int_payment_instrument\")\n",
        "    .withColumn(\"email\", template=r'\\\\w.\\\\w@\\\\w.com')       \n",
        "    .withColumn(\"md5_payment_instrument\", \n",
        "                expr=\"md5(concat(payment_instrument_type, ':', payment_instrument))\",\n",
        "                baseColumn=['payment_instrument_type', 'payment_instrument']) \n",
        ")\n",
        "df1 = dataspec.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML6msILA_zJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d5b69f-8000-4009-aaab-6073de6bb4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------------+------------------+--------------------+----------------------+\n",
            "|                name|payment_instrument_type|payment_instrument|               email|md5_payment_instrument|\n",
            "+--------------------+-----------------------+------------------+--------------------+----------------------+\n",
            "|          laboris ut|                   visa| **** ****** *6187|   qui.enim@esse.com|  56a8392f6ea841439...|\n",
            "|     exercitation in|             mastercard| **** ****** *7390|occaecat.quis@iru...|  56cb6c943fdd51a0a...|\n",
            "|         tempor esse|                 paypal| **** ****** *3256|   sunt.dolor@ut.com|  7149ba8873f8e092e...|\n",
            "|veniam l. consect...|                 paypal| **** ****** *6949|laborum.laborum@q...|  e6008d9e735094d07...|\n",
            "|     incididunt nisi|                   visa| **** ****** *3300|dolore.ipsum@veli...|  30ac2f3a589c42061...|\n",
            "|      cillum ullamco|                   visa| **** ****** *8669|mollit.in@laborum...|  4bc3bce50fca2ba6a...|\n",
            "|          magna nisi|                   visa| **** ****** *6364|nostrud.voluptate...|  5668f2a01c3ae1071...|\n",
            "|dolor t. consectetur|                   visa| **** ****** *1034|   ut.in@laborum.com|  7baab16de229f1276...|\n",
            "|  et k. exercitation|                 paypal| **** ****** *2071|sed.nostrud@dolor...|  137ab84714c046a09...|\n",
            "|        duis w. esse|                   visa| **** ****** *9455| enim.laborum@in.com|  b7d6cdcdcb26ad036...|\n",
            "|             in aute|                   amex| **** ****** *2939|   lorem.aute@ut.com|  b1546f0a2456263f2...|\n",
            "|  exercitation m. ad|                   visa| **** ****** *9892|        in.ut@in.com|  75f248378e6c4c933...|\n",
            "|      voluptate sint|             mastercard| **** ****** *1628|veniam.mollit@ut.com|  a977478054bf84cda...|\n",
            "|      sed adipiscing|             mastercard|  **** ****** *455| fugiat.magna@eu.com|  e1f19f00fe3a3457e...|\n",
            "| fugiat m. consequat|                   visa| **** ****** *2923|dolore.pariatur@l...|  09e0d390f0706a742...|\n",
            "|     magna e. fugiat|             mastercard| **** ****** *6330|  dolore.et@enim.com|  d09ce99be25290eb2...|\n",
            "|  sunt v. incididunt|                   visa| **** ****** *9787|    ut.est@lorem.com|  371678e8f3e46281d...|\n",
            "|incididunt c. ali...|                   visa| **** ****** *7918| dolore.in@ipsum.com|  c289bb79bc53dfa74...|\n",
            "|      fugiat aliquip|                 paypal| **** ****** *1101|nostrud.laborum@i...|  d3b54538c25b5095a...|\n",
            "|          dolor esse|                   visa| **** ****** *8231|  est.duis@dolor.com|  cd98124b37346e97f...|\n",
            "+--------------------+-----------------------+------------------+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OM-v7EoAqZS"
      },
      "source": [
        "### Part IV: Spark for Data Analysis\n",
        "\n",
        "* Рассмотрим операции парсинга, конкатенции, поиска, фильтрации.\n",
        "* Оценим временную сложность основных операций.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-8AhUkqUlm"
      },
      "source": [
        "Для исследования возьмем данные об аэропортах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpCvZSBo2VVE"
      },
      "outputs": [],
      "source": [
        "# Лучше выполнять через Google Chrome\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for fn in uploaded.keys():\n",
        "#    print('User uploaded file «{name}» with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X19_ww9L1Ub0"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"airport-codes.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsLcWZfr3FlC"
      },
      "source": [
        "Spark может считать файлы разных форматов. Вот их неполный список:\n",
        "\n",
        "Файлы:\n",
        "* json\n",
        "* text\n",
        "* csv\n",
        "* parquet\n",
        "\n",
        "Также может считать из разных баз данных и брокеров сообщений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySqAKlxr7Fz8"
      },
      "source": [
        "Считаем csv-данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGs9vN82xjk0"
      },
      "outputs": [],
      "source": [
        "df = spark.read.format(\"csv\").options(header=True, inferSchema=True).load(DATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a35RAqfxIaM3"
      },
      "source": [
        "Выведем первые 5 строк и схему датафрейма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-zLdcpMIZO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de2a301-ce74-4456-8013-74ea8cea74e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
            "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
            "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
            "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
            "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
            "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
            "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
            "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
            "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- ident: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- elevation_ft: integer (nullable = true)\n",
            " |-- continent: string (nullable = true)\n",
            " |-- iso_country: string (nullable = true)\n",
            " |-- iso_region: string (nullable = true)\n",
            " |-- municipality: string (nullable = true)\n",
            " |-- gps_code: string (nullable = true)\n",
            " |-- iata_code: string (nullable = true)\n",
            " |-- local_code: string (nullable = true)\n",
            " |-- coordinates: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF6wRSruyAGD"
      },
      "source": [
        "Чтобы при каждой новой операции (actions в Spark) не вычислялось всё заново, неоходимо использовать __кэширование__. Если этого не сделать, то при каждой новой операции с ним он пересчитывается при вызове каждого действия.\n",
        "\n",
        "Есть методы __cache__ и __persist__. Они сохраняют состояние графа (плана вычислений) после первого действия. И следующие просто обращаются к нему. \n",
        "persist дает выбрать, куда сохранить данные, а cache использует значение по умолчанию (зависит от версии Spark что берется по умолчанию). В текущей версии Spark это [StorageLevel.MEMORY_ONLY](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jruZ2QsfqRVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4cffd3-6775-48f6-8e30-85dd56dc2fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 57421\n"
          ]
        }
      ],
      "source": [
        "df.cache()\n",
        "print(\"count:\", df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V35JEwhgDXYK"
      },
      "source": [
        "Все возможности Spark для чтения есть и для записи. Давайте поэксперементируем с сохранением в разных форматах. Например, __parquet__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyuXTApc9XYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ad6b37-700b-4a61-e35a-45db40bbf482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyspark.sql.functions (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyspark.sql.functions\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark.sql.functions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *"
      ],
      "metadata": {
        "id": "JXowhDBDAuny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/jkbr/httpie.git#egg=httpie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRG-tNbz_aJ3",
        "outputId": "1e49e7cc-7f55-455b-cd5b-47dc7f40fe48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting httpie\n",
            "  Cloning https://github.com/jkbr/httpie.git to /tmp/pip-install-ynbyezv_/httpie_f96dfc38dd3d4b1980fef228fedbc062\n",
            "  Running command git clone -q https://github.com/jkbr/httpie.git /tmp/pip-install-ynbyezv_/httpie_f96dfc38dd3d4b1980fef228fedbc062\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from httpie) (21.1.3)\n",
            "Requirement already satisfied: charset_normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from httpie) (2.0.12)\n",
            "Requirement already satisfied: defusedxml>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from httpie) (0.7.1)\n",
            "Requirement already satisfied: requests[socks]>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from httpie) (2.23.0)\n",
            "Requirement already satisfied: Pygments>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from httpie) (2.6.1)\n",
            "Collecting requests-toolbelt>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting multidict>=4.7.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from httpie) (57.4.0)\n",
            "Collecting rich>=9.10.0\n",
            "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from httpie) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4.0->httpie) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4.0->httpie) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.22.0->httpie) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.22.0->httpie) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.22.0->httpie) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.22.0->httpie) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.22.0->httpie) (1.7.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 4.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: httpie\n",
            "  Building wheel for httpie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httpie: filename=httpie-3.2.1-py3-none-any.whl size=125037 sha256=3eade0d7ac083f27cade0b738c7124d9f15306914ad67e163792f34a203fe121\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ci0wftx2/wheels/aa/0b/c1/46ad6a9f541947b36054d3947824c7d3965d2e2e96290acfe0\n",
            "Successfully built httpie\n",
            "Installing collected packages: commonmark, rich, requests-toolbelt, multidict, httpie\n",
            "Successfully installed commonmark-0.9.1 httpie-3.2.1 multidict-6.0.2 requests-toolbelt-0.9.1 rich-12.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-age-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3oyd2NgBiqQ",
        "outputId": "9d7f7508-83c7-4c15-b7ac-5f23a83c9a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement apache-age-python (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for apache-age-python\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D6CeOcBD2xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785fd36a-70de-41eb-cf70-f912738d848e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok! Data is written to /tmp/agg0.parquet\n"
          ]
        }
      ],
      "source": [
        "condition = col(\"continent\") != \"n/a\"\n",
        "\n",
        "df \\\n",
        "    .filter(condition) \\\n",
        "    .write \\\n",
        "    .format(\"parquet\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .save(\"/tmp/agg0.parquet\")\n",
        "\n",
        "print(\"Ok! Data is written to {}\".format(\"/tmp/agg0.parquet\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sytzj-YiBqe-"
      },
      "source": [
        "####Фильтрация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-NOntYGB7QB"
      },
      "source": [
        "Метод filter позволяет фильтровать датасет:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U96xjikB8Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f5162b-4017-40df-951b-a1d571f63833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------------------------+------------+---------+-----------+----------+----------------+--------+---------+----------+----------------------------------+\n",
            "|ident  |type    |name                     |elevation_ft|continent|iso_country|iso_region|municipality    |gps_code|iata_code|local_code|coordinates                       |\n",
            "+-------+--------+-------------------------+------------+---------+-----------+----------+----------------+--------+---------+----------+----------------------------------+\n",
            "|ABE    |closed  |RAF Calveley             |null        |EU       |GB         |GB-ENG    |Cheshire        |null    |null     |null      |-2.603889, 53.113333              |\n",
            "|ABL    |closed  |RNAS/RAF Calshot         |null        |EU       |GB         |GB-ENG    |Hampshire       |null    |null     |null      |-1.30677223206, 50.8199131549     |\n",
            "|AD-0001|heliport|CamÃ­ Heliport           |null        |EU       |AD         |AD-04     |La Massana      |null    |null     |null      |1.51916, 42.546257                |\n",
            "|AD-ALV |heliport|Andorra la Vella Heliport|3450        |EU       |AD         |AD-07     |Andorra La Vella|null    |ALV      |null      |1.533551, 42.511174               |\n",
            "|ADJ    |closed  |RAF Castletown           |null        |EU       |GB         |GB-SCT    |Caithness       |null    |null     |null      |-3.3481693267800003, 58.5847198881|\n",
            "|AEI    |heliport|Algeciras Heliport       |98          |EU       |ES         |ES-CA     |Algeciras       |LEAG    |AEI      |null      |-5.441118, 36.12888               |\n",
            "|AL-0001|closed  |Lapraka Heliport         |297         |EU       |AL         |AL-11     |Tirana          |null    |null     |null      |19.7913, 41.333302                |\n",
            "|AL-0002|closed  |Lower Koretica Airport   |null        |EU       |XK         |XK-01     |Lower Koretica  |null    |null     |null      |20.909699, 42.605192              |\n",
            "|AL-0003|closed  |Aeroporti i Mifoit       |null        |EU       |AL         |AL-12     |Mifoit          |null    |null     |null      |19.426254, 40.60618               |\n",
            "|AL-LA10|closed  |GjirokastÃ«r Airport     |666         |EU       |AL         |AL-05     |GjirokastÃ«r    |LASK    |null     |null      |20.151917, 40.087889              |\n",
            "+-------+--------+-------------------------+------------+---------+-----------+----------+----------------+--------+---------+----------+----------------------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "CPU times: user 9.07 ms, sys: 2.9 ms, total: 12 ms\n",
            "Wall time: 538 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "df.filter(col(\"continent\") == \"EU\").show(10, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2xeg9OaJXNw"
      },
      "source": [
        "Подготровим датафрейм с очищенными данными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwb24-HtJYDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3262993-f2d8-486d-fc30-0c623740e2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.5 ms, sys: 1.2 ms, total: 16.7 ms\n",
            "Wall time: 303 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "fill_dict = {'continent': 'n/a', 'iata_code': 'n/a'}\n",
        "replace_dict = {\"Rossiya\": \"Russia\", \"NA\": \"n/a\"}\n",
        "\n",
        "clean_data = (\n",
        "    df.dropDuplicates()\n",
        "    .na.drop(\"all\")\n",
        "    .na.fill(fill_dict)\n",
        "    .na.replace(replace_dict)\n",
        "    .select(col(\"continent\"), col(\"name\"), col(\"iso_country\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kNufsNALSYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3718cdc9-3881-43a5-e3fe-589db1aca138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----------+\n",
            "|continent|                name|iso_country|\n",
            "+---------+--------------------+-----------+\n",
            "|      n/a|    Caffrey Heliport|         US|\n",
            "|      n/a|Bailey Generation...|         US|\n",
            "|      n/a|      Hammer Airport|         US|\n",
            "|      n/a|Ac & R Components...|         US|\n",
            "|      n/a| Sands Ranch Airport|         US|\n",
            "+---------+--------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clean_data.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNzazsL4MoYb"
      },
      "source": [
        "#### Группировки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCVyPyftMrz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6ac8c6-4da8-43b4-b1e5-7c1b7a9bdc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|continent|count(1)|\n",
            "+---------+--------+\n",
            "|EU       |8404    |\n",
            "|SA       |8443    |\n",
            "|AN       |28      |\n",
            "|OC       |3123    |\n",
            "|n/a      |28443   |\n",
            "|AF       |3361    |\n",
            "|AS       |5619    |\n",
            "+---------+--------+\n",
            "\n",
            "CPU times: user 23.1 ms, sys: 2.82 ms, total: 25.9 ms\n",
            "Wall time: 1.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from pyspark.sql.functions import count, sum\n",
        "\n",
        "agg = clean_data.groupBy(\"continent\").agg(count(\"*\"))\n",
        "agg.show(10, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82a90WVIJATx"
      },
      "source": [
        "#### Оконные функции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlN1Or98JHsB"
      },
      "source": [
        "Оконные функции позволяют делать функции над \"окнами\" данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFH6PyeYJBmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe2b246-574e-49cd-f155-5984e67c7708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----------+----------+\n",
            "|continent|                name|iso_country|city_count|\n",
            "+---------+--------------------+-----------+----------+\n",
            "|       AF|       Adado Airport|         SO|      3361|\n",
            "|       AF|    El Daein Airport|         SD|      3361|\n",
            "|       AF|Saurimo North Air...|         AO|      3361|\n",
            "|       AF|       Cuchi Airport|         AO|      3361|\n",
            "|       AF|   Namacunde Airport|         AO|      3361|\n",
            "+---------+--------------------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "CPU times: user 30 ms, sys: 4.68 ms, total: 34.7 ms\n",
            "Wall time: 2.81 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from pyspark.sql import Window\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "window = Window.partitionBy(\"continent\")\n",
        "\n",
        "agg = (\n",
        "    clean_data\n",
        "    .withColumn(\"city_count\", F.count(\"*\").over(window))\n",
        ")\n",
        "agg.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6CEn2peNFVb"
      },
      "source": [
        "#### Функции pyspark.sql.functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mnzoBiONFdS"
      },
      "source": [
        "Большим преимуществом Spark по сравнению с большинством SQL ориентированных БД является наличие встроенных функций работы со списками, словарями и структурами данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THdPohUUJNaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39f93b9-74e6-45ee-eaa8-f79d6d56acf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- allinone: struct (nullable = false)\n",
            " |    |-- continent: string (nullable = false)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- iso_country: string (nullable = true)\n",
            " |    |-- city_count: long (nullable = false)\n",
            "\n",
            "+---------------------------------------+\n",
            "|allinone                               |\n",
            "+---------------------------------------+\n",
            "|{AF, Adado Airport, SO, 3361}          |\n",
            "|{AF, El Daein Airport, SD, 3361}       |\n",
            "|{AF, Saurimo North Airport, AO, 3361}  |\n",
            "|{AF, Cuchi Airport, AO, 3361}          |\n",
            "|{AF, Namacunde Airport, AO, 3361}      |\n",
            "|{AF, Chitembo Airport, AO, 3361}       |\n",
            "|{AF, Cangamba Airport, AO, 3361}       |\n",
            "|{AF, Bamburi Airport, KE, 3361}        |\n",
            "|{AF, Mombo Camp Airport, BW, 3361}     |\n",
            "|{AF, Xamaxai Airport, BW, 3361}        |\n",
            "|{AF, Mmashoro Airport, BW, 3361}       |\n",
            "|{AF, Bazaruto Island Airport, MZ, 3361}|\n",
            "|{AF, Djolu Airport, CD, 3361}          |\n",
            "|{AF, Mambasa Airport, CD, 3361}        |\n",
            "|{AF, Monga Airstrip, CD, 3361}         |\n",
            "|{AF, Nia-Nia Airport, CD, 3361}        |\n",
            "|{AF, Aru Airport, CD, 3361}            |\n",
            "|{AF, N'DÃ©lÃ© West Airport, CF, 3361}  |\n",
            "|{AF, Mokabi Airport, CG, 3361}         |\n",
            "|{AF, Touboro Airport, CM, 3361}        |\n",
            "+---------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 32.7 ms, sys: 5.44 ms, total: 38.2 ms\n",
            "Wall time: 2.04 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "all_in_one = agg.select(struct(*agg.columns).alias(\"allinone\"))\n",
        "\n",
        "all_in_one.printSchema()\n",
        "all_in_one.show(20, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Конкатенация\n",
        "\n",
        "Например, можно конкатенировать столбцы датафрейма\n",
        "\n",
        "* `concat()` используется для объединения нескольких столбцов в один столбец без разделителя\n",
        "* `concat_ws()` используется для объединения с разделителем. \n",
        "\n",
        "Эти две функции доступны в модуле `pyspark.sql.functions`."
      ],
      "metadata": {
        "id": "7RQnv5HxybXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "agg = agg.select(\n",
        "    F.concat_ws(\"_\", col(\"name\"), col(\"continent\"), col(\"iso_country\")).alias(\"concat\"),\n",
        "    col(\"city_count\")\n",
        ")\n",
        "agg.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8U3EnIqBUDZ",
        "outputId": "82d4e956-aa9e-40c4-fa05-1266e2b4c820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|              concat|city_count|\n",
            "+--------------------+----------+\n",
            "| Adado Airport_AF_SO|      3361|\n",
            "|El Daein Airport_...|      3361|\n",
            "|Saurimo North Air...|      3361|\n",
            "| Cuchi Airport_AF_AO|      3361|\n",
            "|Namacunde Airport...|      3361|\n",
            "+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "CPU times: user 26.2 ms, sys: 4.38 ms, total: 30.6 ms\n",
            "Wall time: 1.73 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Поиск"
      ],
      "metadata": {
        "id": "HBtOPtW5FbCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "agg = agg.select(col(\"concat\"), col(\"city_count\")).filter(\"city_count > 5000\")\n",
        "agg.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lS5txVDFgo9",
        "outputId": "ca43f6c6-186e-4026-d842-d158c96ffe6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|              concat|city_count|\n",
            "+--------------------+----------+\n",
            "|Al Ghuwaifat Bord...|      5619|\n",
            "|Charikar Airport_...|      5619|\n",
            "|Hongyuan Airport_...|      5619|\n",
            "|  Berd Airport_AS_AM|      5619|\n",
            "|Yas Island Seapla...|      5619|\n",
            "+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "CPU times: user 26.9 ms, sys: 1.77 ms, total: 28.7 ms\n",
            "Wall time: 1.83 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part V: Spark vs Pandas"
      ],
      "metadata": {
        "id": "ShdjV3D7GgUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "(\n",
        "    agg\n",
        "    .select(col(\"concat\"), col(\"city_count\"))\n",
        "    .filter(\"city_count > 10000\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8fFSTt4H7gM",
        "outputId": "613bacbd-298b-4ef9-f39a-9b6297b5ddc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|              concat|city_count|\n",
            "+--------------------+----------+\n",
            "|Caffrey Heliport_...|     28443|\n",
            "|Bailey Generation...|     28443|\n",
            "|Hammer Airport_n/...|     28443|\n",
            "|Ac & R Components...|     28443|\n",
            "|Sands Ranch Airpo...|     28443|\n",
            "|Steel Systems Hel...|     28443|\n",
            "|R J D Heliport_n/...|     28443|\n",
            "|Ferrell Field_n/a_US|     28443|\n",
            "|Mc Kenzie Bridge ...|     28443|\n",
            "|Lower Granite Sta...|     28443|\n",
            "|Ware Island Airpo...|     28443|\n",
            "|Community Hospita...|     28443|\n",
            "|Swansboro Country...|     28443|\n",
            "|Los Angeles Count...|     28443|\n",
            "|Cedar Knoll Flyin...|     28443|\n",
            "|Medical Center He...|     28443|\n",
            "|  Myers Field_n/a_US|     28443|\n",
            "|Hoopeston Communi...|     28443|\n",
            "|Compaq Andover He...|     28443|\n",
            "|Lantana Ranch Air...|     28443|\n",
            "+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "CPU times: user 24.8 ms, sys: 3.9 ms, total: 28.7 ms\n",
            "Wall time: 1.91 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1_pd = agg.toPandas()"
      ],
      "metadata": {
        "id": "5wN95m6UJC8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "df1_pd[df1_pd[\"city_count\"] > 10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "cd4EdwLuIZpa",
        "outputId": "b84d0a17-8d48-43c8-9c7f-9c8cd1a8815a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.89 ms, sys: 3.08 ms, total: 9.97 ms\n",
            "Wall time: 43.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          concat  city_count\n",
              "22466                    Caffrey Heliport_n/a_US       28443\n",
              "22467  Bailey Generation Station Heliport_n/a_US       28443\n",
              "22468                      Hammer Airport_n/a_US       28443\n",
              "22469          Ac & R Components Heliport_n/a_US       28443\n",
              "22470                 Sands Ranch Airport_n/a_US       28443\n",
              "...                                          ...         ...\n",
              "50904             Elgin Municipal Airport_n/a_US       28443\n",
              "50905         Lyall Harbour Seaplane Base_n/a_CA       28443\n",
              "50906        Greenway Sound Seaplane Base_n/a_CA       28443\n",
              "50907                   Opinaca Aerodrome_n/a_CA       28443\n",
              "50908           April Point Seaplane Base_n/a_CA       28443\n",
              "\n",
              "[28443 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e1b932d-5318-4a05-8728-9c118a335af2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concat</th>\n",
              "      <th>city_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22466</th>\n",
              "      <td>Caffrey Heliport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22467</th>\n",
              "      <td>Bailey Generation Station Heliport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22468</th>\n",
              "      <td>Hammer Airport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22469</th>\n",
              "      <td>Ac &amp; R Components Heliport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22470</th>\n",
              "      <td>Sands Ranch Airport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50904</th>\n",
              "      <td>Elgin Municipal Airport_n/a_US</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50905</th>\n",
              "      <td>Lyall Harbour Seaplane Base_n/a_CA</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50906</th>\n",
              "      <td>Greenway Sound Seaplane Base_n/a_CA</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50907</th>\n",
              "      <td>Opinaca Aerodrome_n/a_CA</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50908</th>\n",
              "      <td>April Point Seaplane Base_n/a_CA</td>\n",
              "      <td>28443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28443 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e1b932d-5318-4a05-8728-9c118a335af2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e1b932d-5318-4a05-8728-9c118a335af2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e1b932d-5318-4a05-8728-9c118a335af2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "* PySpark мощный инструмент для работы с большими данными\n",
        "* Обрабатывает данные распределенно на нескольких воркерах\n",
        "* в отличие от RDD, Dataframe API устроен так, что все вычисления происходят в JVM\n",
        "* обладает единым API для работы с различными источниками данных\n",
        "* имеет большой набор встроенных функций работы с данными\n",
        "* имеет возможность использовать в pyspark функции, доступные в Java"
      ],
      "metadata": {
        "id": "GgECVEKBLOUl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BigData.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}